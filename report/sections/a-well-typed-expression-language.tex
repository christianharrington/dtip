%!TEX root = ../main.tex
\section{A Well-Typed Representation}
\label{sec:a-well-typed-expression-language}
% - Definition: Well-typed
% - Representation
% - De Bruijn (HasType)
% - INTERP?

We will begin this section by asking a fundamental question: Why do we want types? Programming in an untyped setting allows for immense freedom of expression, but provides very few guarantees. The cost of this freedom comes at run time, where all bets are off: Your program could terminate successfully, terminate abnormally, or not terminate at all. If we add types into the equation, this picture changes. Types provide static information about the shape and possible values of a term, and this information can be used at compile time to make sure that the internal structure of a program does not cause it to terminate abnormally (naturally, adding types does not solve the halting problem). The additional information can also lead to improved tool support, such as the Emacs modes for Idris\,\cite{Idris:EmacsMode} and Agda\,\cite{AgdaMode}. 

As specified by Milner, a well-typed program does not \emph{go wrong}\,\cite{Milner78atheory}. If we can provide every term with a type, and check that this typing is consistent with the rest of the program, then we can be assured that the program in its entirety does not go wrong. In other words, a type system provides safety. Pierce\,\cite[Section~8.3]{Pierce:TypeSystems} describes the standard technique for proving \emph{type safety} using two lemmas: (1) Progress and (2) Preservation. Progress means that a well-typed term is either a value or that we can take a step of evaluation (i.e. it can always make progress if needed). Preservation says that \emph{if} a term takes a step of evaluation, then the resulting term is also well-typed.

Nevertheless, if we can provide a consistent typing for every term of a program within a type system that is safe, our program does not go wrong, i.e. it will not end up in a stuck state. 

\subsection{Making The Representation Well-Typed}
\label{sec:making-the-representation-well-typed}
As mentioned in the previous section, the main motivation behind defining a well-typed representation is the ability to create terms that are correct by construction, and later, the possibility of defining a well-typed interpreter. This means that whenever we construct a term, we have the added guarantee that it is well-typed. Accordingly, it is impossible to construct a term that is not well-typed. The representation presented here is inspired by Augustsson and Carlsson's approach to defining a well-typed interpreter\,\cite{Augustsson99anexercise}.


\subsubsection{Well-Typed Expressions}
%An expression is well-typed if its subterms are well-typed with respect to their enclosing environment\,\cite{Milner78atheory}. 
%We will see how this property is handled by first considering a well-typed representation of the core simply typed lambda calculus:

Our first goal is to create a well-typed representation of the simply typed lambda calculus. To achieve this, let us first consider the typing rules given in Section~\ref{sec:stlc}. These say that we can construct the term given in the conclusion if all the premises hold. Specifically, they say:

\begin{enumerate}
\item A variable can be constructed if it is defined in the type environment $\Gamma$
\item A lambda abstraction of type $t \to t'$ can be constructed if we can construct a term of type $t'$ that is closed under $\Gamma$ extended by $t$
\item We can construct a term of type $t'$ by applying a term of type $t \to t'$ to a term of type $t$
\end{enumerate}

A well-typed representation needs to be expressive enough to make sure that the above constraints hold whenever we try to construct a term. So what we want is to translate these logical rules to a representation within the type system, ensuring any expressions constructed with these types are correct by construction. A data type representing the typing rules of the simply typed lambda calculus is shown in Figure~\ref{fig:well-typed-stlc}. Here, \texttt{Tip} represents the internal types of the language, i.e. the types that a term can be given.

\begin{figure}
\begin{alltt}
  data Tip = TipUnit | TipBool | TipInt 
           | TipProd Tip Tip | TipSum Tip Tip | TipFun Tip Tip

  data Expr : Vect n Tip \(\rightarrow\) Tip \(\rightarrow\) Type where
    Var : HasType i G t \(\rightarrow\) Expr G t
    Lam : Expr (t :: G) t' \(\rightarrow\) Expr G (TipFun t t')
    App : Expr G (TipFun t t') \(\rightarrow\) Expr G t \(\rightarrow\) Expr G t'
\end{alltt}
\caption{A dependently typed representation of the simply typed lambda calculus. This forms the core of what we call the well-typed representation.}
\label{fig:well-typed-stlc}
\end{figure}

If we examine the typing rules from Section~\ref{sec:stlc} more closely, we will discover that all the terms have two properties in common: (1) they are all defined in the type environment $\Gamma$, and (2) they all have a type. The important observation here is that the definition of a term \emph{depends} on these two. Accordingly, we can construct a dependent type \texttt{Expr} which depends on a type environment \texttt{Vect n Tip} (corresponding to $\Gamma$) and a type \texttt{Tip}. Recall from Section~\ref{sec:dependent-types-idris} that a term of type \texttt{Vect n a} is a vector containing \texttt{n} elements of type \texttt{a}. As such, the type of the type environment should make sense. To convince ourselves that this representation is in fact well-typed, let us map our representation to our three earlier observations:

\begin{enumerate}
\item A \texttt{Var} of type $t$ can be constructed if \texttt{HasType i G t} holds
\item A \texttt{Lam} of type \texttt{TipFun t t'} can be constructed if we can construct a term of type $t'$ that is closed under $G$ where $t$ is added
\item We can construct an \texttt{Expr G t'} by applying an \texttt{Expr G t} to an \texttt{Expr G (TipFun t t')}
\end{enumerate}

The \texttt{Var} case may not be intuitive at first sight --- We will return to it shortly. The \texttt{Lam} case is a straightforward translation of the typing rule, where the cons (\texttt{::}) constructor of the \texttt{Vect} representing the type environment is used for extending $G$ with $t$. The \texttt{App} case is equally unsurprising.

\paragraph{}
Now before we delve into greater details about this implementation, the seasoned Haskell user might point out that the above implementation could have been done entirely using a generalized algebraic data type (GADT), avoiding the use of dependent types. A possible Haskell implementation is given in Figure~\ref{fig:stlc-GADT} (of course, a similar implementation could have been given in any language supporting GADTs).

\begin{figure}
\begin{alltt}
data Expr :: * \(\rightarrow\) * where
  gVar :: Integer \(\rightarrow\) Expr Integer
  gLam :: (Expr a \(\rightarrow\) Expr b) \(\rightarrow\) Expr (a \(\rightarrow\) b)
  gApp :: Expr (a \(\rightarrow\) b) \(\rightarrow\) Expr a \(\rightarrow\) Expr b 
\end{alltt}
\caption{Definition of the simply typed lambda calculus using a GADT. The names of the constructors have been prefixed with a 'g' to avoid confusion with the previously defined Idris data type}
\label{fig:stlc-GADT}
\end{figure}

This representation using higher-order abstract syntax seems quite strong, but GADTs only allow us to have types parameterized over types, while a dependently typed language allows for types to be parameterized over terms. As such, all the $a$'s and $b$'s in Figure~\ref{fig:stlc-GADT} are \emph{types}. In Haskell (as in most languages), totality is not enforced, so non-exhaustive pattern matches are compiled without warning by default. This means that nothing prevents us from writing an expression like \texttt{gLam (\textbackslash{x} $\rightarrow$ case x of gVar y $\rightarrow$ gVar y}). While this works fine as long as \texttt{x} matches \texttt{gVar y}, an exception occurs if we apply any other arguments. Accordingly, our earlier observation regarding the \texttt{App} case no longer holds: We cannot always construct another expression when applying a term to a \texttt{gLam}, as the function which the \texttt{gLam} is parameterized over might be partial. Partiality is discussed in-depth in Section~\ref{sec:partiality}. Furthermore, nothing prevents us from calling meta-language (Haskell, in this case) operations which are not available in the object language, which might lead to unexpected results. For now, the important point is that a dependently typed representation provides us with added safety, because lambda abstractions are not defined as Idris functions, but instead are modeled by adding a \emph{term} of type $t$ to the type environment $G$ (see Figure~\ref{fig:well-typed-stlc}).

\subsubsection{Variables}
Picking up where we left off, we will now discuss why the \texttt{Var} case in Figure~\ref{fig:well-typed-stlc} is well-typed. Remember that our initial observation about the typing rule for variables was that a variable can be constructed if it is defined in the type environment $\Gamma$. However, ``is defined'' is quite vague, and we need to precisely describe what it means for a variable to be defined in a type environment in a rigorous way. This is where \texttt{HasType} comes in, as it acts a membership predicate on a type environment. \texttt{HasType} is given in Figure~\ref{fig:HasType}.

\begin{figure}
\begin{alltt}
  data HasType : (i : Fin n) \(\to\) Vect n Tip \(\to\) Tip \(\to\) Type where
    stop : HasType fZ (t :: G) t
    pop  : HasType k G t \(\to\) HasType (fS k) (u :: G) t
\end{alltt}
\caption{The \texttt{HasType} membership predicate.}
\label{fig:HasType}
\end{figure}

We model variables using de Bruijn indices\,\cite{Bruijn72lambdacalculus}. \texttt{HasType} is an inductively defined relation over de Bruijn indices (\texttt{Fin n}), type environments (\texttt{Vect n Tip}), and types (\texttt{Tip}). The intuition is that it models the premise $x~:~\tau~\in~\Gamma$ of the \textsc{T-Var} typing rule presented in Section~\ref{sec:stlc}. It does this by defining two constructors: \texttt{stop} and \texttt{pop}. The use of \texttt{HasType} is perhaps best illustrated by an example, which is provided in Figure~\ref{fig:HasType-use}. 

\begin{figure}
\begin{alltt}
  a : Expr G (TipFun TipInt TipInt)
  a = Lam (Var stop)                              -- equivalent to \(\lambda.0\)
  b : Expr G (TipFun (TipFun TipInt TipBool) (TipFun TipInt TipBool))
  b = Lam (Lam (App (Var (pop stop)) (Var stop))) -- equivalent to \(\lambda.\lambda.1 0\)
\end{alltt}
\caption{Use of \texttt{HasType}.}
\label{fig:HasType-use}
\end{figure}

This illustration shows that we refer to the last bound variable (\texttt{0}) using \texttt{stop}, the next to last bound variable (\texttt{1}) using \texttt{pop stop}, and so on, adding a \texttt{pop} whenever we go one abstraction up. In this respect, the structure of \texttt{HasType} resembles that of the natural numbers which was introduced in Section~\ref{sec:dependent-types-idris}. Note that \texttt{HasType} only models the premise of the typing rule for variables, and must therefore be wrapped in a \texttt{Var} in order to become a term in the language.

To be convinced that variables are correct by construction using the \texttt{HasType} predicate, we must discuss both typing and scoping. Whenever a variable is constructed, its internal type (created by a constructor of \texttt{Tip}) is inferred from the type annotation on its enclosing term. Consequently, the variable in the first example of Figure~\ref{fig:HasType-use} has type \texttt{TipInt}. In the second example, \texttt{pop stop} (and hence \texttt{Var (pop stop)}) is given the type \texttt{TipFun TipInt TipBool}, while \texttt{stop} is given the type \texttt{TipInt}. Since all types are inferred from the context, it is impossible to annotate an expression with a type that does not match the way the variables are used. For instance, in Figure~\ref{fig:HasType-use}, \texttt{pop stop} has to have the type \texttt{TipFun x y}. Otherwise the Idris type checker will not accept it. It should be noted from the definition of \texttt{HasType} (see Figure~\ref{fig:HasType}) that the type of a \texttt{HasType} never changes, even when \texttt{pop}s are added or removed. 

A correctly constructed variable must not only be well-typed, but also in scope. The definition of \texttt{HasType} tells us that neither \texttt{stop} nor \texttt{pop} can be constructed on an empty environment, as they both pattern match on the structure of the type environment in their types. Thus, we cannot reference variables from an empty environment, as an environment matching the cons (\texttt{::}) case is expected. Furthermore, we saw in Figure~\ref{fig:well-typed-stlc} that the \texttt{Lam} case is parameterized over a term which adds a type to the environment. This means that types are added to the environment when lambda abstractions are added, and removed when we go under a lambda abstraction. As such, we cannot reference variables that are out of scope, as this would mean constructing a \texttt{HasType} proof on an empty environment, which is impossible due to its definition. 

We will conclude our discussion of variables by considering the distinction between free and bound variables. Both free and bound variables reside in the same environment, $G$. In an expression with \textit{n} lambda abstractions, the first \textit{n} variables in the environment are bound, while the remaining occur free. The total number of variables is bounded by the structure of the expression and the number of types in the initial environment.


\subsubsection{The Full Representation}
As mentioned in Section~\ref{sec:the-simply-typed-lambda-calculus}, we extend the simply typed lambda calculus with several standard extensions. A well-typed representation of the language in its entirety is shown in Figure~\ref{fig:idris-def-expr-lang}, and most of the cases should be immediately understandable. Only the \texttt{Case} case is somewhat interesting, as it adds a variable to the type environment in each of its branches. Since going into one of these branches is equivalent to going under a lambda abstraction, the properties of variables and lambda abstractions presented in this section directly translates to this case as well.

\begin{figure}
\begin{alltt}
  data Expr : Vect n Tip \(\rightarrow\) Tip \(\rightarrow\) Type where
    U    : Expr G TipUnit
    Var  : HasType i G t \(\rightarrow\) Expr G t
    Val  : (i : Int) \(\rightarrow\) Expr G TipInt
    Boo  : (b : Bool) \(\rightarrow\) Expr G TipBool
    Lam  : Expr (t :: G) t' \(\rightarrow\) Expr G (TipFun t t')
    App  : Expr G (TipFun t t') \(\rightarrow\) Expr G t \(\rightarrow\) Expr G t'
    If   : Expr G TipBool \(\rightarrow\) Expr G t \(\rightarrow\) Expr G t \(\rightarrow\) Expr G t
    Pair : Expr G a \(\rightarrow\) Expr G b \(\rightarrow\) Expr G (TipProd a b)
    Fst  : Expr G (TipProd a b) \(\rightarrow\) Expr G a
    Snd  : Expr G (TipProd a b) \(\rightarrow\) Expr G b
    InL  : Expr G a \(\rightarrow\) (b: Tip) \(\rightarrow\) Expr G (TipSum a b)
    InR  : Expr G b \(\rightarrow\) (a: Tip) \(\rightarrow\) Expr G (TipSum a b)
    Case : Expr G (TipSum a b) \(\rightarrow\) Expr (a :: G) c \(\rightarrow\)
           Expr (b :: G) c \(\rightarrow\) Expr G c
    OpU  : UnOp a b \(\rightarrow\) Expr G a \(\rightarrow\) Expr G b
    OpB  : BinOp a b c \(\rightarrow\) Expr G a \(\rightarrow\) Expr G b \(\rightarrow\) Expr G c
    Fix  : Expr G (TipFun t t) \(\rightarrow\) Expr G t
\end{alltt}
\caption{Idris definition of the well-typed representation.}
\label{fig:idris-def-expr-lang}
\end{figure}


% The definition of \texttt{Expr} specifies that any term is represented in the type system by (1) its enclosing environment of \textit{n} (de Bruijn-indexed) variables and (2) an internal type, i.e. a \texttt{Tip}. To make the distinction clear, we denote inhabitants of \texttt{Tip} as internal types, and all other Idris types as external types.

% To see why this representation is well-typed, consider the typing rules for the simply typed lambda calculus given in Section~\ref{sec:stlc}. 

% A variable is specified by its internal type in the environment. As such, we can only construct terms which are typed with respect to their enclosing environment. For atomic terms (values with no subterms), this property is sufficient to claim well-typedness. It is insufficient for terms with subterms, however, as these must also be well-typed.

% MENTION TYPE REFINEMENT AND ENV
% DESCRIBE WHY THIS REPRESENTATION IS WELL-TYPED
% MENTION DIFFERENCE --- GADT
% Pass empty type to GADT

% Type rules are encoded as predicates
% Curry-Howard

% \begin{enumerate}
% \item Referencing a variable that is not in scope
% \item Applying a function with an argument of the wrong type
% \item Applying an argument to a term that is not a function
% \end{enumerate}


% Variables are represented by a membership predicate (\texttt{HasType}) on its enclosing environment. These will be discussed in-depth in the next subsection. Lambda abstractions (\texttt{Lam}) are parameterized by its body under a bound variable, and application (\texttt{App}) is parameterized by an expression of function type \texttt{TipFun t t'} and a parameter of type \texttt{t}, the argument type of the first parameter. Notably, none of these terms can be constructed without providing well-typed subterms which are also consistently typed with respect to their (sub-)subterms and their enclosing environments\todo{David siger: "Why not?"}.

% Recall that if we can type every term \emph{and} check that this typing is consistent, our program does not go wrong. What the definition of the \texttt{Expr} type is really saying is that we cannot construct any term \emph{unless} its typing is consistent\todo{David siger: "what do you mean by consistent?"}. We rely on the internal Idris type checker to make sure that our program does not type check if we try to type any term inconsistently. So when we say we construct terms which are correct by construction, it is implied that the type of each term is consistent by construction\todo{David siger: "Everything you've done so far is achievable using GADTs, isn't it? Point out the difference, or at least that a difference is coming. "}.

 

% \subsubsection{Variables}
% %well-scoped - membership predicate HasType
% %free vs bound
% %REF - De Bruijn

% A variable in the well-typed representation is parameterized by a membership predicate, \texttt{HasType} (shown in Figure~\ref{fig:HasType}), on its enclosing environment. The predicate models de Bruijn indices\,\cite{Bruijn72lambdacalculus}, and can be seen as a way to provide an intrinsic proof that a variable at a given position has a certain type. Figure~\ref{fig:HasType-use} shows an example of its practical use. Note that HasType's constructors are similar to those of Nat, except their indices give strong guarantees.




% The use of \texttt{HasType} is an example of creating variables that are correct by construction. It is only possible to construct \texttt{HasType} instances which are both well-typed and well-scoped:
% \begin{itemize}
% \item If we look at the type of \texttt{stop}, it will always have the same type as the first variable in the environment --- this type can be deduced from the top-level annotation\todo{David siger: "I thought the annotration was elsewhere. Your Lam in fig 7 doesn't have a type annot"} of the lambda expression. In fact, a \texttt{HasType} predicate will always have a specific type which is consistent with the top-level type annotation, and thus it is well-typed. Idris's type system will detect any inconsistent use of a variable. 
% \item Only lambda abstractions and case-expressions on sum types push new variables onto the environment, which can be seen from their constructors: \texttt{Expr (t :: G) t' \(\rightarrow\) Expr G (TipFun t t')} and \texttt{Expr G (TipSum a b) \(\rightarrow\) Expr (a :: G) c \(\rightarrow\) Expr (b :: G) c \(\rightarrow\) Expr G c}. It is not possible to reference a variable which exceeds the number of these enclosing it. Therefore, it must be well-scoped. This argument still holds if an explicit initial environment is passed to an expression, as such an environment can always be substituted with an equivalent number of lambda abstractions.
% \end{itemize}

% \paragraph{Free and bound variables} 

\subsection{Interpreting the Language}
The challenge of interpreting the well-typed representation is that we do not want to lose the guarantee of well-typedness in the process. In general, our goal is to map each term of the language (defined in Figure~\ref{fig:idris-def-expr-lang}) to an equivalent Idris term. As suggested by Augustsson and Carlsson\,\cite{Augustsson99anexercise}, a na\"{i}ve implementation might simply define the resulting type of an interpreter for this representation as a sum type (wrapped in a \texttt{Maybe}), such as the Value type shown in Figure \ref{fig:naive-interpreter-impl}.

\begin{figure}
\begin{alltt}
data Value : Type where
  VBool : Int \(\to\) Value
  VInt  : Bool \(\to\) Value

interp : Expr G t \(\to\) Maybe Value
interp (Val i) = VInt i
interp (Boo b) = VBool b
interp (If c tb fb) with (interp c)
  | Just (VBool True)  = interp tb
  | Just (VBool False) = interp fb
  | Nothing            = Nothing
\end{alltt}
\caption{A na\"{i}ve and incomplete implementation of an interpreter for the language.}
\label{fig:naive-interpreter-impl}
\end{figure}

However, such an interpreter has several shortcomings. First, given an \texttt{Expr} term, we have no static guarantee that we interpret it as an Idris term that makes sense. For instance, there is no compile-time guarantee that \texttt{interp (Boo True)} does not always result in \texttt{VInt 0}. Secondly, the type system cannot statically enforce that the resulting values are well-typed. In the \texttt{If}-case, we have to check whether the condition is in fact interpreted as a boolean. Otherwise, interpretation is undefined, which we handle by wrapping the resulting type in a \texttt{Maybe}. In a dependently typed setting, we can do much better, by using the expressive power of the type system to our advantage.

\subsubsection{A Universe of Types}
% Power of Pi
Following Brady's example\,\cite{Brady:IdrisTutorial}, we first define a universe of internal types (\texttt{Tip}). Generally speaking, a universe is a pair consisting of (1) a type of descriptions of types, called \emph{codes}, and (2) an interpretation function that maps the codes to actual types.\,\cite{Oury:2008}. We have already defined a code type \texttt{Tip} to describe our internal types in Figure~\ref{fig:well-typed-stlc}. Figure~\ref{fig:interpTip} shows the interpretation function for our universe, \texttt{interpTip}.

\begin{figure}
\begin{alltt}
interpTip : Tip \(\to\) Type
interpTip TipUnit        = ()
interpTip TipBool        = Bool
interpTip TipInt         = Int
interpTip (TipProd T T') = (interpTip T, interpTip T')
interpTip (TipSum T T')  = Either (interpTip T) (interpTip T')
interpTip (TipFun T T')  = interpTip T \(\to\) interpTip T'
\end{alltt}
\caption{The \texttt{interpTip} decoding function for our universe of internal types.}
\label{fig:interpTip}
\end{figure}

\texttt{interpTip} is an example of a function that actually returns a type. We use the built-in \texttt{Either} type to model sum types, and use the standard Idris notation for defining function types, $\to$. This universe is used to define our well-typed interpreter, as shown in Figure~\ref{fig:well-typed-interpreter}.

\begin{figure}
\begin{alltt}
data Env : Vect n Tip \(\to\) Type where
  Nil  : Env Nil
  (::) : interpTip a \(\to\) Env G \(\to\) Env (a :: G)

lookup : HasType i G t \(\to\) Env G \(\to\) interpTip t
lookup stop    (x :: xs) = x
lookup (pop k) (x :: xs) = lookup k xs

interp : Env G \(\to\) Expr G t \(\to\) interpTip t
interp env (Val i)   = i
interp env (Var i)   = lookup i env
interp env (Lam b)   = \textbackslash{x} => interp (x :: env) b
interp env (App f a) = interp env f (interp env a)
\vdots
\end{alltt}
\caption{An incomplete implementation of a well-typed interpreter for the language, with less interesting cases omitted. Notice that in the \texttt{Lam} case, the function returns an Idris lambda expression.}
\label{fig:well-typed-interpreter}
\end{figure}

The result type of the \texttt{interp} function is now much more expressive than the previous definition: it depends on the internal type of the input expression. Now, we know that all \texttt{Expr} terms will be reduced to a term of the corresponding Idris type, according to the semantics of the \texttt{interpTip} function. To fully appreciate the power of \texttt{interp}, it is important to note that \texttt{interpTip} is evaluated by the type checker. Having the type checker evaluate functions is one of the great benefits of dependently typed programming. It is not necessary to prove the correspondence to the specification, because the computational behavior of the language is used by the type checker. In this case, it allows us to create types from terms, determining a suitable return type for each case of \texttt{interp}.

Another interesting observation from Figure~\ref{fig:well-typed-interpreter} is how the handling of variables (through \texttt{Env} and \texttt{lookup}) and the reduction semantics of Idris together perform the interpretation of well-typed terms. At first sight, the definition of the \texttt{Env} data type seems unintuitive: How can we get an \texttt{interpTip a}, when \texttt{Env} only stores \texttt{a}? The key here is that pattern matching causes type refinement. When the type checker sees a pattern match on \texttt{Env} (as in the \texttt{Lam} case), it can not only infer the specific type of \texttt{a}, but also run the \texttt{interpTip} function on that \texttt{a}, such that the proper \texttt{Type} can be returned. This mechanism can also be utilized using GADTs in Haskell. However, in this case we would only be able to refine \texttt{a} to a specific type. The dependently typed setting allows us to run functions on this specific type as well, adding an extra level of expressiveness.

In order to better understand lookup (and the \texttt{interp} function in general), consider the example in Figure~\ref{fig:well-typed-interpreter-example}. Here, $\Rightarrow$ should be read as ``reduces to''. As the parameter type of the lambda abstraction and the type of the variable \texttt{Var stop} is the same by construction, the body of the lambda abstraction can be reduced to \texttt{x} through \texttt{lookup}, yielding the identity function as expected. The Idris type system ensures that this reduction will always be consistent with the input expression, as the result depends on the input through the return type of \texttt{interp}, \texttt{interpTip t}. Furthermore, we do not need to handle undefined cases, since the type system can predict the resulting type of all reductions (as long as the interpretation function is total).

\begin{figure}
\begin{alltt}
interp Nil (App (Lam (Var stop)) (Val 5))
\(\Rightarrow\) (interp Nil (Lam (Var stop))) (interp Nil (Val 5))
\(\Rightarrow\) (\textbackslash{x} => interp (x :: Nil) (Var stop)) 5
\(\Rightarrow\) (\textbackslash{x} => lookup stop (x :: Nil)) 5
\(\Rightarrow\) (\textbackslash{x} => x) 5
\(\Rightarrow\) 5
\end{alltt}
\caption{An example execution of the \texttt{interp} function on an empty initial environment.}
\label{fig:well-typed-interpreter-example}
\end{figure}

While this scheme seems to be quite powerful, it falls short when we introduce general recursion to the language. Section~\ref{sec:partiality} provides a further investigation into this problem. Next, we will show how we can convert a raw representation of the simply typed lambda calculus into an equivalent well-typed representation through type checking, thus demonstrating that the type checker is correct by construction.
